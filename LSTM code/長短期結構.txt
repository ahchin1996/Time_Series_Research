def create_model_talos(train_data, train_label, x_val, y_val, params):
    BATCH_SIZE = params["batch_size"]
    EPOCHS = params["epochs"]
    lstm_model = Sequential()
    # (batch_size, timesteps, data_dim)
    lstm_model.add(LSTM(params["lstm1_nodes"], input_shape=(1 ,train_data.shape[2]), return_sequences=True))

    if params["lstm_layers"] == 2:
        lstm_model.add(LSTM(params["lstm2_nodes"], return_sequences = True))
        lstm_model.add(Flatten())
    else:
        lstm_model.add(Flatten())
    lstm_model.add(Dense(1))

    if params["optimizer"] == 'Adam':
        optimizer = Adam(lr=params["lr"])

    lstm_model.compile(loss='mean_squared_error', optimizer=optimizer, metrics = ['acc'])  # binary_crossentropy
    history = lstm_model.fit(train_data,
                             train_label,
                             epochs = EPOCHS,
                             verbose=2,
                             batch_size=BATCH_SIZE,
                             validation_data=[x_val,y_val]
                             )
    # for key in history.history.keys():
    #     print(key, "--",history.history[key])
    print_time("program running in", stime)
    print()
    return history, lstm_model